{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/is11085/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Natural Language Processing (NLP) is a fascinating field that combines linguistics, computer science, and artificial intelligence to enable machines to understand and process human language. \\n\\nIt involves tasks such as tokenization—where text is split into individual words or phrases—and part-of-speech tagging, which assigns grammatical categories to each word. \\n\\nNamed entity recognition identifies and classifies key elements, like names and dates, within the text. \\n\\nSentiment analysis is another crucial aspect: determining the emotional tone behind a body of text. \\n\\nNLP applications are vast, ranging from chatbots and virtual assistants to language translation and sentiment analysis tools. \\n\\nSpecial characters like @, #, and $ can be used to test the robustness of NLP models in handling social media data and financial documents!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "CORPUS = \"\"\"Natural Language Processing (NLP) is a fascinating field that combines linguistics, computer science, and artificial intelligence to enable machines to understand and process human language. \\n\\nIt involves tasks such as tokenization—where text is split into individual words or phrases—and part-of-speech tagging, which assigns grammatical categories to each word. \\n\\nNamed entity recognition identifies and classifies key elements, like names and dates, within the text. \\n\\nSentiment analysis is another crucial aspect: determining the emotional tone behind a body of text. \\n\\nNLP applications are vast, ranging from chatbots and virtual assistants to language translation and sentiment analysis tools. \\n\\nSpecial characters like @, #, and $ can be used to test the robustness of NLP models in handling social media data and financial documents!\"\"\"\n",
    "CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization : Para -> Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "documents = sent_tokenize(CORPUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization : Para -> Words / Sent -> Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'fascinating',\n",
       " 'field',\n",
       " 'that',\n",
       " 'combines',\n",
       " 'linguistics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'process',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'tokenization—where',\n",
       " 'text',\n",
       " 'is',\n",
       " 'split',\n",
       " 'into',\n",
       " 'individual',\n",
       " 'words',\n",
       " 'or',\n",
       " 'phrases—and',\n",
       " 'part-of-speech',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'which',\n",
       " 'assigns',\n",
       " 'grammatical',\n",
       " 'categories',\n",
       " 'to',\n",
       " 'each',\n",
       " 'word',\n",
       " '.',\n",
       " 'Named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " 'identifies',\n",
       " 'and',\n",
       " 'classifies',\n",
       " 'key',\n",
       " 'elements',\n",
       " ',',\n",
       " 'like',\n",
       " 'names',\n",
       " 'and',\n",
       " 'dates',\n",
       " ',',\n",
       " 'within',\n",
       " 'the',\n",
       " 'text',\n",
       " '.',\n",
       " 'Sentiment',\n",
       " 'analysis',\n",
       " 'is',\n",
       " 'another',\n",
       " 'crucial',\n",
       " 'aspect',\n",
       " ':',\n",
       " 'determining',\n",
       " 'the',\n",
       " 'emotional',\n",
       " 'tone',\n",
       " 'behind',\n",
       " 'a',\n",
       " 'body',\n",
       " 'of',\n",
       " 'text',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'applications',\n",
       " 'are',\n",
       " 'vast',\n",
       " ',',\n",
       " 'ranging',\n",
       " 'from',\n",
       " 'chatbots',\n",
       " 'and',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " 'to',\n",
       " 'language',\n",
       " 'translation',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'tools',\n",
       " '.',\n",
       " 'Special',\n",
       " 'characters',\n",
       " 'like',\n",
       " '@',\n",
       " ',',\n",
       " '#',\n",
       " ',',\n",
       " 'and',\n",
       " '$',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'test',\n",
       " 'the',\n",
       " 'robustness',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'models',\n",
       " 'in',\n",
       " 'handling',\n",
       " 'social',\n",
       " 'media',\n",
       " 'data',\n",
       " 'and',\n",
       " 'financial',\n",
       " 'documents',\n",
       " '!']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(CORPUS)\n",
    "(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization: Paras/Sent -> Words{punctuations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'fascinating',\n",
       " 'field',\n",
       " 'that',\n",
       " 'combines',\n",
       " 'linguistics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'process',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'tokenization',\n",
       " '—',\n",
       " 'where',\n",
       " 'text',\n",
       " 'is',\n",
       " 'split',\n",
       " 'into',\n",
       " 'individual',\n",
       " 'words',\n",
       " 'or',\n",
       " 'phrases',\n",
       " '—',\n",
       " 'and',\n",
       " 'part',\n",
       " '-',\n",
       " 'of',\n",
       " '-',\n",
       " 'speech',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'which',\n",
       " 'assigns',\n",
       " 'grammatical',\n",
       " 'categories',\n",
       " 'to',\n",
       " 'each',\n",
       " 'word',\n",
       " '.',\n",
       " 'Named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " 'identifies',\n",
       " 'and',\n",
       " 'classifies',\n",
       " 'key',\n",
       " 'elements',\n",
       " ',',\n",
       " 'like',\n",
       " 'names',\n",
       " 'and',\n",
       " 'dates',\n",
       " ',',\n",
       " 'within',\n",
       " 'the',\n",
       " 'text',\n",
       " '.',\n",
       " 'Sentiment',\n",
       " 'analysis',\n",
       " 'is',\n",
       " 'another',\n",
       " 'crucial',\n",
       " 'aspect',\n",
       " ':',\n",
       " 'determining',\n",
       " 'the',\n",
       " 'emotional',\n",
       " 'tone',\n",
       " 'behind',\n",
       " 'a',\n",
       " 'body',\n",
       " 'of',\n",
       " 'text',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'applications',\n",
       " 'are',\n",
       " 'vast',\n",
       " ',',\n",
       " 'ranging',\n",
       " 'from',\n",
       " 'chatbots',\n",
       " 'and',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " 'to',\n",
       " 'language',\n",
       " 'translation',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'tools',\n",
       " '.',\n",
       " 'Special',\n",
       " 'characters',\n",
       " 'like',\n",
       " '@,',\n",
       " '#,',\n",
       " 'and',\n",
       " '$',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'test',\n",
       " 'the',\n",
       " 'robustness',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'models',\n",
       " 'in',\n",
       " 'handling',\n",
       " 'social',\n",
       " 'media',\n",
       " 'data',\n",
       " 'and',\n",
       " 'financial',\n",
       " 'documents',\n",
       " '!']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "words_punct = wordpunct_tokenize(CORPUS)\n",
    "(words_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#,', '-', '@,', 'part', 'phrases', 'speech', 'tokenization', 'where', '—'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(words_punct) - set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization : Para -> Words (Punctuation considered with the word itself and not as different word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'fascinating',\n",
       " 'field',\n",
       " 'that',\n",
       " 'combines',\n",
       " 'linguistics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'process',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'tokenization—where',\n",
       " 'text',\n",
       " 'is',\n",
       " 'split',\n",
       " 'into',\n",
       " 'individual',\n",
       " 'words',\n",
       " 'or',\n",
       " 'phrases—and',\n",
       " 'part-of-speech',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'which',\n",
       " 'assigns',\n",
       " 'grammatical',\n",
       " 'categories',\n",
       " 'to',\n",
       " 'each',\n",
       " 'word.',\n",
       " 'Named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " 'identifies',\n",
       " 'and',\n",
       " 'classifies',\n",
       " 'key',\n",
       " 'elements',\n",
       " ',',\n",
       " 'like',\n",
       " 'names',\n",
       " 'and',\n",
       " 'dates',\n",
       " ',',\n",
       " 'within',\n",
       " 'the',\n",
       " 'text.',\n",
       " 'Sentiment',\n",
       " 'analysis',\n",
       " 'is',\n",
       " 'another',\n",
       " 'crucial',\n",
       " 'aspect',\n",
       " ':',\n",
       " 'determining',\n",
       " 'the',\n",
       " 'emotional',\n",
       " 'tone',\n",
       " 'behind',\n",
       " 'a',\n",
       " 'body',\n",
       " 'of',\n",
       " 'text.',\n",
       " 'NLP',\n",
       " 'applications',\n",
       " 'are',\n",
       " 'vast',\n",
       " ',',\n",
       " 'ranging',\n",
       " 'from',\n",
       " 'chatbots',\n",
       " 'and',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " 'to',\n",
       " 'language',\n",
       " 'translation',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'tools.',\n",
       " 'Special',\n",
       " 'characters',\n",
       " 'like',\n",
       " '@',\n",
       " ',',\n",
       " '#',\n",
       " ',',\n",
       " 'and',\n",
       " '$',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'test',\n",
       " 'the',\n",
       " 'robustness',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'models',\n",
       " 'in',\n",
       " 'handling',\n",
       " 'social',\n",
       " 'media',\n",
       " 'data',\n",
       " 'and',\n",
       " 'financial',\n",
       " 'documents',\n",
       " '!']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "treebank_tokens = treebank_tokenizer.tokenize(CORPUS)\n",
    "treebank_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-Tut-fo0Vo1Jx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
